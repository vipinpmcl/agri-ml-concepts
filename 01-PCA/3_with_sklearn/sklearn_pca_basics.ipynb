{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sklearn's PCA - The Professional Way\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that we understand PCA from scratch, let's learn to use sklearn's optimized implementation.\n",
    "\n",
    "### What You'll Learn\n",
    "1. How to use `sklearn.decomposition.PCA`\n",
    "2. Key parameters and their effects\n",
    "3. Important attributes after fitting\n",
    "4. How to determine optimal number of components\n",
    "5. Best practices for real-world applications\n",
    "\n",
    "### Why sklearn?\n",
    "- **Optimized**: Uses efficient SVD algorithm\n",
    "- **Well-tested**: Industry standard\n",
    "- **Feature-rich**: Many useful options\n",
    "- **Integrated**: Works seamlessly with sklearn pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple 2D data\n",
    "np.random.seed(42)\n",
    "X = np.array([\n",
    "    [2.5, 2.4],\n",
    "    [0.5, 0.7],\n",
    "    [2.2, 2.9],\n",
    "    [1.9, 2.2],\n",
    "    [3.1, 3.0],\n",
    "    [2.3, 2.7],\n",
    "    [2.0, 1.6],\n",
    "    [1.0, 1.1]\n",
    "])\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(X)\n",
    "print(f\"\\nShape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"\\nPCA Results:\")\n",
    "print(f\"Transformed data shape: {X_pca.shape}\")\n",
    "print(f\"\\nExplained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total variance explained: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"\\nComponents (eigenvectors):\\n{pca.components_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Key Parameters\n",
    "\n",
    "### n_components\n",
    "Most important parameter - determines dimensionality of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different n_components\n",
    "print(\"Testing different n_components:\\n\")\n",
    "\n",
    "# Keep all components\n",
    "pca_all = PCA()\n",
    "pca_all.fit(X)\n",
    "print(f\"n_components=None: {pca_all.n_components_} components\")\n",
    "print(f\"  Variance: {pca_all.explained_variance_ratio_}\")\n",
    "\n",
    "# Keep 1 component\n",
    "pca_1 = PCA(n_components=1)\n",
    "pca_1.fit(X)\n",
    "print(f\"\\nn_components=1: {pca_1.n_components_} component\")\n",
    "print(f\"  Variance: {pca_1.explained_variance_ratio_}\")\n",
    "\n",
    "# Keep 95% variance\n",
    "pca_95 = PCA(n_components=0.95)\n",
    "pca_95.fit(X)\n",
    "print(f\"\\nn_components=0.95: {pca_95.n_components_} components selected\")\n",
    "print(f\"  Variance: {pca_95.explained_variance_ratio_}\")\n",
    "print(f\"  Total: {pca_95.explained_variance_ratio_.sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Important Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore PCA attributes\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "\n",
    "print(\"Important PCA Attributes:\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n1. components_ (shape {pca.components_.shape}):\")\n",
    "print(\"   Principal axes in feature space\")\n",
    "print(pca.components_)\n",
    "\n",
    "print(f\"\\n2. explained_variance_ (shape {pca.explained_variance_.shape}):\")\n",
    "print(\"   Amount of variance explained by each component\")\n",
    "print(pca.explained_variance_)\n",
    "\n",
    "print(f\"\\n3. explained_variance_ratio_ (shape {pca.explained_variance_ratio_.shape}):\")\n",
    "print(\"   Percentage of variance explained\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(f\"\\n4. singular_values_ (shape {pca.singular_values_.shape}):\")\n",
    "print(\"   Singular values from SVD\")\n",
    "print(pca.singular_values_)\n",
    "\n",
    "print(f\"\\n5. mean_ (shape {pca.mean_.shape}):\")\n",
    "print(\"   Per-feature mean\")\n",
    "print(pca.mean_)\n",
    "\n",
    "print(f\"\\n6. n_components_: {pca.n_components_}\")\n",
    "print(f\"7. n_features_: {pca.n_features_}\")\n",
    "print(f\"8. n_samples_: {pca.n_samples_}\")\n",
    "print(f\"9. noise_variance_: {pca.noise_variance_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Determining Optimal Number of Components\n",
    "\n",
    "Three common approaches:\n",
    "1. Explained variance threshold (e.g., 95%)\n",
    "2. Scree plot (elbow method)\n",
    "3. Domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a richer dataset for demonstration\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "print(\"Iris Dataset:\")\n",
    "print(f\"Samples: {X_iris.shape[0]}\")\n",
    "print(f\"Features: {X_iris.shape[1]}\")\n",
    "print(f\"Feature names: {feature_names}\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_iris_scaled = scaler.fit_transform(X_iris)\n",
    "\n",
    "print(\"\\nâœ“ Data standardized (important for PCA!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with all components\n",
    "pca_full = PCA()\n",
    "X_iris_pca = pca_full.fit_transform(X_iris_scaled)\n",
    "\n",
    "print(\"PCA Results on Iris:\")\n",
    "print(f\"\\nExplained variance ratio by component:\")\n",
    "for i, var in enumerate(pca_full.explained_variance_ratio_, 1):\n",
    "    print(f\"  PC{i}: {var:.4f} ({var*100:.2f}%)\")\n",
    "\n",
    "cumulative_var = np.cumsum(pca_full.explained_variance_ratio_)\n",
    "print(f\"\\nCumulative explained variance:\")\n",
    "for i, var in enumerate(cumulative_var, 1):\n",
    "    print(f\"  First {i} PC(s): {var:.4f} ({var*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scree plot and cumulative variance plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Scree plot\n",
    "ax1.bar(range(1, len(pca_full.explained_variance_ratio_) + 1),\n",
    "       pca_full.explained_variance_ratio_,\n",
    "       alpha=0.7, color='steelblue', edgecolor='black', linewidth=2)\n",
    "ax1.plot(range(1, len(pca_full.explained_variance_ratio_) + 1),\n",
    "        pca_full.explained_variance_ratio_,\n",
    "        'ro-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Principal Component', fontsize=12)\n",
    "ax1.set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "ax1.set_title('Scree Plot', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(1, len(pca_full.explained_variance_ratio_) + 1))\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Cumulative variance plot\n",
    "ax2.plot(range(1, len(cumulative_var) + 1), cumulative_var,\n",
    "        'o-', linewidth=2, markersize=8, color='darkgreen')\n",
    "ax2.axhline(y=0.95, color='r', linestyle='--', linewidth=2, label='95% threshold')\n",
    "ax2.axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='90% threshold')\n",
    "ax2.fill_between(range(1, len(cumulative_var) + 1), 0, cumulative_var,\n",
    "                alpha=0.2, color='green')\n",
    "ax2.set_xlabel('Number of Components', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
    "ax2.set_title('Cumulative Explained Variance', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(1, len(cumulative_var) + 1))\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Recommendation\n",
    "n_95 = np.argmax(cumulative_var >= 0.95) + 1\n",
    "print(f\"\\nðŸ’¡ Recommendation: Use {n_95} components for 95% variance retention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization in PCA Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_iris_2d = pca_2d.fit_transform(X_iris_scaled)\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['red', 'blue', 'green']\n",
    "target_names = iris.target_names\n",
    "\n",
    "for i, color, target_name in zip([0, 1, 2], colors, target_names):\n",
    "    plt.scatter(X_iris_2d[y_iris == i, 0],\n",
    "               X_iris_2d[y_iris == i, 1],\n",
    "               color=color, alpha=0.7, s=80,\n",
    "               edgecolors='k', linewidths=0.5,\n",
    "               label=target_name)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca_2d.explained_variance_ratio_[0]:.2%} variance)', fontsize=13)\n",
    "plt.ylabel(f'PC2 ({pca_2d.explained_variance_ratio_[1]:.2%} variance)', fontsize=13)\n",
    "plt.title('Iris Dataset in PCA Space', fontsize=15, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ’¡ The 3 iris species are well-separated in PCA space!\")\n",
    "print(f\"   PC1 and PC2 together explain {(pca_2d.explained_variance_ratio_.sum())*100:.1f}% variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inverse Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct data from 2 components\n",
    "X_reconstructed = pca_2d.inverse_transform(X_iris_2d)\n",
    "\n",
    "# Calculate reconstruction error\n",
    "mse = np.mean((X_iris_scaled - X_reconstructed) ** 2)\n",
    "print(f\"Reconstruction MSE (2 components): {mse:.6f}\")\n",
    "\n",
    "# Compare original vs reconstructed for first sample\n",
    "print(f\"\\nFirst sample comparison:\")\n",
    "print(f\"Original (scaled): {X_iris_scaled[0]}\")\n",
    "print(f\"Reconstructed:     {X_reconstructed[0]}\")\n",
    "print(f\"Difference:        {X_iris_scaled[0] - X_reconstructed[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance in PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze component loadings\n",
    "components_df = pd.DataFrame(\n",
    "    pca_2d.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=feature_names\n",
    ")\n",
    "\n",
    "print(\"Component Loadings:\")\n",
    "print(components_df)\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Larger absolute values = feature contributes more to that PC\")\n",
    "print(\"- Sign indicates direction of contribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize loadings\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# PC1 loadings\n",
    "ax1.barh(feature_names, components_df['PC1'], color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Loading Value', fontsize=12)\n",
    "ax1.set_title('PC1 Feature Loadings', fontsize=13, fontweight='bold')\n",
    "ax1.axvline(0, color='black', linewidth=0.8)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# PC2 loadings\n",
    "ax2.barh(feature_names, components_df['PC2'], color='coral', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xlabel('Loading Value', fontsize=12)\n",
    "ax2.set_title('PC2 Feature Loadings', fontsize=13, fontweight='bold')\n",
    "ax2.axvline(0, color='black', linewidth=0.8)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ This shows which original features contribute most to each PC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PCA Best Practices:\\n\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. ALWAYS standardize features before PCA\")\n",
    "print(\"   - Use StandardScaler for features with different scales\")\n",
    "print(\"   - PCA is sensitive to feature magnitudes\")\n",
    "\n",
    "print(\"\\n2. Choose n_components wisely:\")\n",
    "print(\"   - Start with 95% variance threshold\")\n",
    "print(\"   - Use scree plot to find 'elbow'\")\n",
    "print(\"   - Consider computational constraints\")\n",
    "\n",
    "print(\"\\n3. Interpret results:\")\n",
    "print(\"   - Examine component loadings\")\n",
    "print(\"   - Visualize in PC space\")\n",
    "print(\"   - Check if separations make domain sense\")\n",
    "\n",
    "print(\"\\n4. Handle missing values:\")\n",
    "print(\"   - Impute before PCA (PCA can't handle NaN)\")\n",
    "print(\"   - Or use specialized missing data PCA\")\n",
    "\n",
    "print(\"\\n5. Use in pipelines:\")\n",
    "print(\"   - Integrate with sklearn Pipeline\")\n",
    "print(\"   - Combine with other preprocessing\")\n",
    "print(\"   - Useful for hyperparameter tuning\")\n",
    "\n",
    "print(\"\\n6. Watch for:\")\n",
    "print(\"   - Outliers (can dominate PCs)\")\n",
    "print(\"   - Non-linear relationships (consider kernel PCA)\")\n",
    "print(\"   - Categorical variables (encode properly first)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **sklearn PCA is easy**: Just fit and transform!\n",
    "2. **Key parameters**: `n_components` (most important)\n",
    "3. **Important attributes**: `components_`, `explained_variance_ratio_`\n",
    "4. **Determining components**: Use scree plot or variance threshold\n",
    "5. **Always standardize**: Critical for meaningful PCA\n",
    "6. **Interpret carefully**: Look at loadings and visualizations\n",
    "\n",
    "### When to Use PCA\n",
    "\n",
    "- **Visualization**: Reduce to 2D/3D for plotting\n",
    "- **Noise reduction**: Keep signal, discard noise\n",
    "- **Speed up models**: Fewer features = faster training\n",
    "- **Feature engineering**: Create meaningful combinations\n",
    "- **Multicollinearity**: Remove correlated features\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook:\n",
    "- Compare our implementation with sklearn\n",
    "- Verify they produce identical results\n",
    "- Understand performance differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Great job!** You now know how to use sklearn's PCA like a pro.\n",
    "\n",
    "Continue to: `comparison_scratch_vs_sklearn.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
