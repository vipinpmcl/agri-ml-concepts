{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Data Exploration - Agricultural PCA Application\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the practical application! We'll explore real soil data before applying PCA.\n",
    "\n",
    "### What You'll Learn\n",
    "1. Load and inspect soil dataset\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Understand feature correlations\n",
    "4. Data preprocessing for PCA\n",
    "5. Why PCA is useful for soil data\n",
    "\n",
    "### The Dataset\n",
    "200 soil samples with:\n",
    "- Physical properties (texture, moisture)\n",
    "- Chemical properties (pH, NPK, micronutrients)\n",
    "- Derived properties (CEC, EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "print('âœ“ Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Load the Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load soil data\n",
    "data_path = '../../../datasets/soil/sample_soil_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('Soil Dataset Loaded')\n",
    "print('=' * 60)\n",
    "print(f'Samples: {len(df)}')\n",
    "print(f'Features: {len(df.columns)}')\n",
    "print(f'\\nColumn names:')\n",
    "for col in df.columns:\n",
    "    print(f'  - {col}')\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('First 5 samples:')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print('Dataset Information:')\n",
    "print('=' * 60)\n",
    "df.info()\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('Missing values:')\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print('âœ“ No missing values!')\n",
    "else:\n",
    "    print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Basic Statistics"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print('Column Types:')\n",
    "print(f'Numeric: {len(numeric_cols)}')\n",
    "print(f'Categorical: {len(categorical_cols)}')\n",
    "\n",
    "print('\\nStatistical Summary:')\n",
    "df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical distributions\n",
    "print('Categorical Variable Distributions:')\n",
    "print('=' * 60)\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f'\\n{col}:')\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Distribution Visualizations"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key nutrients\n",
    "key_features = ['pH', 'nitrogen_ppm', 'phosphorus_ppm', 'potassium_ppm', \n",
    "               'organic_matter_percent', 'moisture_percent']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(key_features):\n",
    "    axes[idx].hist(df[col], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label='Mean')\n",
    "    axes[idx].axvline(df[col].median(), color='green', linestyle='--', linewidth=2, label='Median')\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ðŸ’¡ These distributions help us understand the typical ranges for each soil property')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Correlation Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "           center=0, square=True, linewidths=1, cbar_kws={'shrink': 0.8})\n",
    "plt.title('Soil Features Correlation Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nðŸ’¡ Key Observations:')\n",
    "print('  â€¢ Strong correlations suggest redundancy - perfect for PCA!')\n",
    "print('  â€¢ NPK nutrients often correlate (soil fertility factor)')\n",
    "print('  â€¢ Texture components are related (constrained to sum to 100%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highly correlated pairs\n",
    "print('Highly Correlated Feature Pairs (|r| > 0.7):')\n",
    "print('=' * 60)\n",
    "\n",
    "high_corr = []\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr.append((\n",
    "                correlation_matrix.columns[i],\n",
    "                correlation_matrix.columns[j],\n",
    "                correlation_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "high_corr.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "for feat1, feat2, corr in high_corr[:10]:  # Top 10\n",
    "    print(f'{feat1:25} <-> {feat2:25} : {corr:6.3f}')\n",
    "\n",
    "print(f'\\nTotal pairs with |r| > 0.7: {len(high_corr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Scatter Plots of Key Relationships"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "\n",
    "# N vs P\n",
    "axes[0, 0].scatter(df['nitrogen_ppm'], df['phosphorus_ppm'], \n",
    "                  alpha=0.6, s=50, edgecolors='k', linewidths=0.5)\n",
    "axes[0, 0].set_xlabel('Nitrogen (ppm)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Phosphorus (ppm)', fontsize=12)\n",
    "axes[0, 0].set_title('Nitrogen vs Phosphorus', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# P vs K\n",
    "axes[0, 1].scatter(df['phosphorus_ppm'], df['potassium_ppm'],\n",
    "                  alpha=0.6, s=50, edgecolors='k', linewidths=0.5, color='coral')\n",
    "axes[0, 1].set_xlabel('Phosphorus (ppm)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Potassium (ppm)', fontsize=12)\n",
    "axes[0, 1].set_title('Phosphorus vs Potassium', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Organic Matter vs CEC\n",
    "axes[1, 0].scatter(df['organic_matter_percent'], df['cec_meq_100g'],\n",
    "                  alpha=0.6, s=50, edgecolors='k', linewidths=0.5, color='green')\n",
    "axes[1, 0].set_xlabel('Organic Matter (%)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('CEC (meq/100g)', fontsize=12)\n",
    "axes[1, 0].set_title('Organic Matter vs CEC', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Clay vs CEC\n",
    "axes[1, 1].scatter(df['clay_percent'], df['cec_meq_100g'],\n",
    "                  alpha=0.6, s=50, edgecolors='k', linewidths=0.5, color='brown')\n",
    "axes[1, 1].set_xlabel('Clay (%)', fontsize=12)\n",
    "axes[1, 1].set_ylabel('CEC (meq/100g)', fontsize=12)\n",
    "axes[1, 1].set_title('Clay vs CEC', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('ðŸ’¡ These correlations show redundancy - we can reduce dimensions with PCA!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Feature Scaling Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature scales\n",
    "print('Feature Scale Comparison:')\n",
    "print('=' * 60)\n",
    "\n",
    "scales = df[numeric_cols].describe().loc[['mean', 'std', 'min', 'max']]\n",
    "print(scales.T)\n",
    "\n",
    "print('\\nðŸ’¡ Notice the huge scale differences!')\n",
    "print('  â€¢ pH: 5-8 range')\n",
    "print('  â€¢ Potassium: 50-400 range')\n",
    "print('  â€¢ Iron: 20-200 range')\n",
    "print('\\n  â†’ We MUST standardize before PCA!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7. Prepare Data for PCA"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Extract features for PCA (exclude IDs and categorical)\n",
    "features_for_pca = [col for col in numeric_cols \n",
    "                   if col not in ['sample_id']]\n",
    "\n",
    "X = df[features_for_pca].values\n",
    "feature_names = features_for_pca\n",
    "\n",
    "print(f'Features for PCA: {len(feature_names)}')\n",
    "print('\\nFeature list:')\n",
    "for i, name in enumerate(feature_names, 1):\n",
    "    print(f'  {i:2d}. {name}')\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f'\\nOriginal data shape: {X.shape}')\n",
    "print(f'Scaled data shape: {X_scaled.shape}')\n",
    "print('\\nâœ“ Data standardized (mean=0, std=1)')\n",
    "\n",
    "# Verify standardization\n",
    "print(f'\\nMeans after scaling: {X_scaled.mean(axis=0)}')\n",
    "print(f'Stds after scaling:  {X_scaled.std(axis=0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 8. Save Preprocessed Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for next notebooks\n",
    "import pickle\n",
    "\n",
    "data_dict = {\n",
    "    'X_scaled': X_scaled,\n",
    "    'X_original': X,\n",
    "    'feature_names': feature_names,\n",
    "    'scaler': scaler,\n",
    "    'df': df,\n",
    "    'categorical_cols': categorical_cols\n",
    "}\n",
    "\n",
    "with open('soil_data_preprocessed.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "\n",
    "print('âœ“ Preprocessed data saved to: soil_data_preprocessed.pkl')\n",
    "print('\\nThis will be used in the next notebooks for PCA analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **Dataset Structure**: 200 soil samples, 16 numeric features\n",
    "2. **High Correlations**: Many features are correlated (redundancy)\n",
    "3. **Scale Differences**: Features span very different ranges\n",
    "4. **Perfect for PCA**: Correlations + many features = great PCA candidate\n",
    "\n",
    "### Why PCA is Useful Here\n",
    "\n",
    "- **Reduce complexity**: 16 features â†’ 2-3 components\n",
    "- **Remove redundancy**: Correlated nutrients combined\n",
    "- **Enable visualization**: Can plot in 2D/3D\n",
    "- **Reveal patterns**: Find underlying soil quality factors\n",
    "- **Interpretability**: Components may represent fertility, texture, etc.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Now we'll:\n",
    "1. Apply PCA to this soil data\n",
    "2. Interpret the components\n",
    "3. Visualize in reduced dimensions\n",
    "4. Extract agronomic insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Great work!** Data is explored and ready for PCA.\n",
    "\n",
    "Continue to: `soil_pca_analysis.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
